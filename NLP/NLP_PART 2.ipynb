{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bde59e-c678-4478-8b56-8ab8642176a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40613e46-6acf-4439-8a3c-05930ec42a86",
   "metadata": {},
   "source": [
    "# NLU:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de50dbca-6f7e-4930-a2b1-0b68c58f3d1f",
   "metadata": {},
   "source": [
    "# TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09dbb284-233f-46d4-96c2-63965bf32e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI = '''Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\n",
    "humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\n",
    "problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\n",
    "It is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\n",
    "AI could solve major challenges and crisis situations.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af21b4f-7049-4ea3-a286-9ffe9006adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize,blankline_tokenize,WhitespaceTokenizer,wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a454cf-53ce-4ece-afe3-62f2889484c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_tokens=word_tokenize(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f4b531-366b-4c13-bf7d-d07c858cd406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de36a8a-261a-4ba1-aa16-6707eb30c0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines.',\n",
       " 'This is in contrast to the natural intelligence of\\nhumans and animals.',\n",
       " 'With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving.',\n",
       " 'Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.',\n",
       " 'It is probably the fastest-growing development in the World of technology and innovation.',\n",
       " 'Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_sent=sent_tokenize(AI)\n",
    "AI_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36912573-9443-45f9-91ed-59c6972a3abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_blank=blankline_tokenize(AI)\n",
    "AI_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86577eb-f1a4-4a4d-a2e4-2e977c3930bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence,',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning,',\n",
       " 'planning,',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving.',\n",
       " 'Most',\n",
       " 'noteworthy,',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation.',\n",
       " 'Furthermore,',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt=WhitespaceTokenizer().tokenize(AI) #comma, full stop gone\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b44666c-3e0b-4f57-878c-47aec3279550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(wt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408d1191-6a16-472f-95d5-ac0425e32d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good apple cost $3.88 in hyderabad. Please buy two oh them . Thanks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='Good apple cost $3.88 in hyderabad. Please buy two oh them . Thanks'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a071a7b6-7199-4151-96a8-0303ee2d2d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'apple',\n",
       " 'cost',\n",
       " '$',\n",
       " '3',\n",
       " '.',\n",
       " '88',\n",
       " 'in',\n",
       " 'hyderabad',\n",
       " '.',\n",
       " 'Please',\n",
       " 'buy',\n",
       " 'two',\n",
       " 'oh',\n",
       " 'them',\n",
       " '.',\n",
       " 'Thanks']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9809abb7-a88e-4ac7-b94e-9f40fb3aa34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem',\n",
       " '-',\n",
       " 'solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest',\n",
       " '-',\n",
       " 'growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_p=wordpunct_tokenize(AI)\n",
    "w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513779a0-2a88-410d-af0d-d765198933bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "print(len(w_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9acc5583-e418-4e40-b3e8-8c1f76f83b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.util import bigrams,trigrams,ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ec4da6-6a07-44ec-bd2e-6597a86b8729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'are', 'student', 'of', 'prakash', 'senapati', 'from', '530pm', 'batch']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string='We are student of prakash senapati from 530pm batch'\n",
    "quotes_tokens=nltk.word_tokenize(string)\n",
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7423794-bc38-4328-a2f9-ea69e213bd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(quotes_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e918aa-a9f4-4f47-ae60-5ca75a6bc4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'are'),\n",
       " ('are', 'student'),\n",
       " ('student', 'of'),\n",
       " ('of', 'prakash'),\n",
       " ('prakash', 'senapati'),\n",
       " ('senapati', 'from'),\n",
       " ('from', '530pm'),\n",
       " ('530pm', 'batch')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_bigrams=list(nltk.bigrams(quotes_tokens)) # Bi grams---2-2 data\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94518d1c-ecfd-4354-806a-56abf58cd631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'are', 'student'),\n",
       " ('are', 'student', 'of'),\n",
       " ('student', 'of', 'prakash'),\n",
       " ('of', 'prakash', 'senapati'),\n",
       " ('prakash', 'senapati', 'from'),\n",
       " ('senapati', 'from', '530pm'),\n",
       " ('from', '530pm', 'batch')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_trigrams=list(nltk.trigrams(quotes_tokens))  # Tri grams---3-3 data\n",
    "quotes_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66a8adbb-60aa-4cfc-8d49-a1e66c668d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'are', 'student', 'of', 'prakash', 'senapati', 'from', '530pm'),\n",
       " ('are', 'student', 'of', 'prakash', 'senapati', 'from', '530pm', 'batch')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_ngrams=list(nltk.ngrams(quotes_tokens,8))  # N grams---n >3 data\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf06dc-8248-47bc-bf8f-30b985ab211b",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22e78e48-0d46-4ae1-8732-3ff3f085991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer #will give root word\n",
    "pst=PorterStemmer() # removes 'ing' oe 'ed' if there is...if not word remains same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2626a123-eaf0-49f2-b319-19e2d0470375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('affection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd4e5127-4b5f-4e13-968d-6a886b068576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('PLAYING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "919c46dd-73f0-44e9-9d21-00a20a8928a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maximium'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('maximium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a8741d4-4f0d-4841-84c7-a7b625c1df4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : give\n",
      "given : given\n",
      "gave : gave\n",
      "gaved : gave\n",
      "thinking : think\n",
      "loving : love\n",
      "maximum : maximum\n",
      "Divyanshu : divyanshu\n"
     ]
    }
   ],
   "source": [
    "words_to_stem=['give','giving','given','gave','gaved','thinking','loving','maximum','Divyanshu']\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+' : ' +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2e5d541-394e-476b-9243-73663b197100",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=LancasterStemmer() # give co root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "447a5a49-0b85-445e-8daf-e3ae1f3d4923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : giv\n",
      "giving : giv\n",
      "given : giv\n",
      "gave : gav\n",
      "gaved : gav\n",
      "thinking : think\n",
      "loving : lov\n",
      "maximum : maxim\n",
      "divyanshu : divyanshu\n"
     ]
    }
   ],
   "source": [
    "words_to_stem=['give','giving','given','gave','gaved','thinking','loving','maximum','divyanshu']\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+' : ' +lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd2049d-c4a9-4347-9291-8bd7bb4cc3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbst=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12ca89c7-9086-4f1b-95be-e7ab98e249f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : give\n",
      "given : given\n",
      "gave : gave\n",
      "gaved : gave\n",
      "thinking : think\n",
      "loving : love\n",
      "maximum : maximum\n",
      "divyanshu : divyanshu\n"
     ]
    }
   ],
   "source": [
    "words_to_stem=['give','giving','given','gave','gaved','thinking','loving','maximum','divyanshu']\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+' : ' + sbst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48ee94-14f1-492e-9bb2-83e1da97453d",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82448039-bbc5-4dd4-966c-bda203b65408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet,WordNetLemmatizer # Will give complete word \n",
    "word_lenm=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "971060e9-35c6-4a14-bb8a-eac211969b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_lem=['give','giving','given','gave','gaved','think','loving','maximum','divyanshu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d78701b-e919-487f-a7a4-84d27a4a2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : giving\n",
      "given : given\n",
      "gave : gave\n",
      "gaved : gaved\n",
      "think : think\n",
      "loving : loving\n",
      "maximum : maximum\n",
      "divyanshu : divyanshu\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_lem:\n",
    "    print(words+' : ' + word_lenm.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d20b9789-ae71-4540-a13d-f657ab8029ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english') #german , spanish, french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cb59003-744e-47fa-83df-21e63ca54ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sam', 'is', 'a', 'natural', 'when', 'it', 'comes', 'to', 'drawing']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent='sam is a natural when it comes to drawing'\n",
    "sent_tokens=word_tokenize(sent)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c361a80-696d-44c7-9790-cc349939fc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sam', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))  #POS tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c19b88c-3636-4436-b517-157771999560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john', 'is', 'eating', 'a', 'delicious', 'cake']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2='john is eating a delicious cake'\n",
    "sent2_tokens=word_tokenize(sent2)\n",
    "sent2_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d10d6f35-a983-4d9b-bec1-06000387d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('john', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('eating', 'VBG')]\n",
      "[('a', 'DT')]\n",
      "[('delicious', 'JJ')]\n",
      "[('cake', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent2_tokens:\n",
    "    print(nltk.pos_tag([token])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b42d55a-0e1b-4a28-9684-71f76a208368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk   #NER -Named Entity Recognistion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f5608b3-5f56-4a68-9adb-0c76e0380e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_sent='The US president stays in the WhiteHouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2dd0fd5-4a68-4578-9e59-8fa7cc6e927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'US', 'president', 'stays', 'in', 'the', 'WhiteHouse']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_tokens=word_tokenize(ne_sent)\n",
    "ne_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "814a03fd-a3da-47eb-b52f-f34d44f745a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('US', 'NNP'), ('president', 'NN'), ('stays', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('WhiteHouse', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "ne_tags=nltk.pos_tag(ne_tokens)\n",
    "print(ne_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013bfb8-9ace-4ce7-8995-5487a72b4986",
   "metadata": {},
   "source": [
    "# Embedding  text--> number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4519632-4a5c-4c97-957f-4e04f8f6c42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 4, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentence='Data science and ai genai has greate carrer ahead data '\n",
    "vectorizer=CountVectorizer()\n",
    "vector=vectorizer.fit_transform([sentence])\n",
    "vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c5ef1a-51f9-4441-9c15-9c2c85824826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24253563, 0.24253563, 0.24253563, 0.24253563, 0.72760688,\n",
       "        0.24253563, 0.24253563, 0.24253563, 0.24253563]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sentence='Data science and ai genai has greate carrer ahead data data '\n",
    "vectorizer=TfidfVectorizer()\n",
    "vector=vectorizer.fit_transform([sentence])\n",
    "vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ecf6f1-3db3-46cd-8000-84ec099790b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
